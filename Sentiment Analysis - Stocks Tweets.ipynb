{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# For sentiment analysis\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as sia\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS OF STOCK TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dadai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ast import Return\n",
    "from textblob import TextBlob\n",
    "\n",
    "# To read configs\n",
    "import configparser\n",
    "\n",
    "# To extarct the twitter data\n",
    "import tweepy as tw\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Datetime manipulations\n",
    "import datetime as dt\n",
    "\n",
    "# Import a needed packages\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# To be applied to the output to convert it to a probability range between 0-1\n",
    "from scipy.special import softmax \n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Remove emojis\n",
    "import demoji\n",
    " \n",
    "\n",
    "# text processing libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "# authentication\n",
    "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract tweets for specific user name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "limit =2500\n",
    "start = dt.datetime(2019,9,14)\n",
    "end = dt.datetime(2022,9,23)\n",
    "data = []\n",
    "columns_name = ['Date','User','Tweet Content']\n",
    "\n",
    "\n",
    "# Define a function for tweets exactration\n",
    "def extract_tweets(username):\n",
    "    # Collect tweets, adding the needed parameters for your specific needed\n",
    "    tweets = tw.Cursor(api.user_timeline,screen_name = username, count = 200, tweet_mode ='extended').items(limit)\n",
    "    #Create a dataframe for tweets \n",
    "    global columns\n",
    "    global data \n",
    "    global commentaries\n",
    "    #Extract the tweets and other needed contents\n",
    "    for comments in tweets:\n",
    "        data.append([comments.created_at,comments.user.screen_name,comments.full_text])\n",
    "        # Create the dataframe\n",
    "        commentaries = pd.DataFrame(data, columns = columns_name)\n",
    "        # Convert the tweets content to lower case for greater accessibility and context\n",
    "        commentaries['Tweet Content'] = commentaries['Tweet Content'].str.casefold()\n",
    "        # Show the dataframe \n",
    "        Return (commentaries)\n",
    "\n",
    "\n",
    "# Create an empty df to stroe merged extracts\n",
    "empty_df = pd.DataFrame(columns=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract for a list of users\n",
    "user = ['GoldmanSachs','jpmorgan','BofA_Business','WellsFargo','Citi']\n",
    "\n",
    "for values in user:\n",
    "    extract_tweets(values)\n",
    "    df1 = empty_df.append(commentaries)\n",
    "\n",
    "\n",
    "# Convert it to Date\n",
    "df1['Date'] = df1['Date'].dt.date\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## _START FROM HERE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>our president and coo john waldron discusses t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-25</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>listen to brex co-ceo @hdubugras on scaling bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>following china’s national congress, our chief...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          User                                      Tweet Content\n",
       "0 2022-10-26  GoldmanSachs  our president and coo john waldron discusses t...\n",
       "1 2022-10-25  GoldmanSachs  listen to brex co-ceo @hdubugras on scaling bu...\n",
       "2 2022-10-24  GoldmanSachs  following china’s national congress, our chief..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For consistency, the same tweet extracted as at the time of writing this was reimported directly.\n",
    "\n",
    "df1 = pd.read_excel(r'Tweets.xlsx')\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>First Date</th>\n",
       "      <th>Last Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BofA_Business</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>2017-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Citi</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>2019-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WellsFargo</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>2022-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>2018-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User First Date  Last Date\n",
       "0  BofA_Business 2022-10-26 2017-08-23\n",
       "1           Citi 2022-10-26 2019-08-29\n",
       "2   GoldmanSachs 2022-10-26 2020-05-21\n",
       "3     WellsFargo 2022-10-27 2022-09-01\n",
       "4       jpmorgan 2022-10-26 2018-02-20"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the least date captured and to which user\n",
    "rslt = df1.loc[df1['Date'] == min(df1['Date'])]\n",
    "\n",
    "\n",
    "# Create a table that aggregates the group by the date posted\n",
    "df2 = (df1.groupby(['User'], as_index=False)\n",
    "        .agg(**{'First Date':('Date', 'first'),\n",
    "                'Last Date': ('Date', 'last')}))\n",
    "\n",
    "# display\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords filter for the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>rt @podcast_maze: new episode out now with pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>how are top investors navigating today’s volat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>steve and connie ballmer's investment bridges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>rt @squawkcnbc: \"we've got a leading investmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>today we reported our 3q 2022 earnings results...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Citi</td>\n",
       "      <td>the financial agent mentor-protégé program bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Citi</td>\n",
       "      <td>\"citi’s $72 million investment in our new stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Citi</td>\n",
       "      <td>rt @politicopress: can america become a leader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494</th>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>Citi</td>\n",
       "      <td>what are some of the most pressing regulatory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>Citi</td>\n",
       "      <td>in the september issue of @thebanker, #citi co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2784 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          User  \\\n",
       "4     2022-10-21  GoldmanSachs   \n",
       "5     2022-10-20  GoldmanSachs   \n",
       "6     2022-10-19  GoldmanSachs   \n",
       "8     2022-10-18  GoldmanSachs   \n",
       "9     2022-10-18  GoldmanSachs   \n",
       "...          ...           ...   \n",
       "12477 2019-09-09          Citi   \n",
       "12484 2019-09-05          Citi   \n",
       "12486 2019-09-05          Citi   \n",
       "12494 2019-09-04          Citi   \n",
       "12495 2019-09-03          Citi   \n",
       "\n",
       "                                           Tweet Content  \n",
       "4      rt @podcast_maze: new episode out now with pet...  \n",
       "5      how are top investors navigating today’s volat...  \n",
       "6      steve and connie ballmer's investment bridges ...  \n",
       "8      rt @squawkcnbc: \"we've got a leading investmen...  \n",
       "9      today we reported our 3q 2022 earnings results...  \n",
       "...                                                  ...  \n",
       "12477  the financial agent mentor-protégé program bui...  \n",
       "12484  \"citi’s $72 million investment in our new stat...  \n",
       "12486  rt @politicopress: can america become a leader...  \n",
       "12494  what are some of the most pressing regulatory ...  \n",
       "12495  in the september issue of @thebanker, #citi co...  \n",
       "\n",
       "[2784 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To test for my 3rd challenge of finding tweets which contains certain words of interest\n",
    "new_df = df1[df1['Tweet Content'].str.contains('algo|anti-city|anti-dilution|anti-speculation|anti-speculative|arbitrage|arbitrageur|asset management|asset-stripping|bagger|bear|bear market|bearish|blue-chip|bond|bourse|broker|bull|bull market|bullish|buy something in|buyback|callable|capital investment|carpetbagger|cash|cash out|cashout|city|copper-bottomed|crash|dead cat bounce|dealing|delist|dilution|disinvest|disinvestment|distributable|diversified|dividend|Dow Jones|electricals|equity|faller|Fibonacci |flotation |footsie |fund management |fund manager |future |gainer |gilt |go public idiom |growth-oriented |grubstake |haircut |head fake |hedging |holding |ICO |industrial |initial coin offering |insider dealing |intangible asset |investment |issue |list |listed company |mature |maturity |negotiable |non-directional|non-discretionary|non-distributable|non-rated |non-speculative |noncallable |nondiversified |OFEX |option |outgain |over-investment |par |payback period |plan |portfolio |post-crash |principal |public |pyramid scheme |pyramid selling |quant |redeemable |rentier |repurchase |rig| rig the market idiom |rogue trader |security |seed money |share |shareholder |small cap |sound |speculation |speculative |speculatively |spread betting |stag |stake |stakeholder |stock |stock exchange |stock market |stockbroker |stockbroker belt |stockbroking |stockholder |strip |subscribe |tender |the Big Board |the FTSE 100 |the grey market |the Nikkei index |the S&P 500 |S&P 500 |the Square Mile |trade |trader |trading |Treasury bond |unissued |unit trust |unlisted |venture capital |venture capitalist |Wall Street|administred prices | employment | inflation | aggregate demand | energy price | inflation | inflation rate | borrowing growth | energy prices |  inflationary pressure | broad money | equity prices | inflationary pressures')]\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>rt @podcast_maze: new episode out now with pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>how are top investors navigating today’s volat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>steve and connie ballmer's investment bridges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>rt @squawkcnbc: \"we've got a leading investmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>today we reported our 3q 2022 earnings results...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Citi</td>\n",
       "      <td>the financial agent mentor-protégé program bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Citi</td>\n",
       "      <td>\"citi’s $72 million investment in our new stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>Citi</td>\n",
       "      <td>rt @politicopress: can america become a leader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494</th>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>Citi</td>\n",
       "      <td>what are some of the most pressing regulatory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>Citi</td>\n",
       "      <td>in the september issue of @thebanker, #citi co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2784 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          User  \\\n",
       "4     2022-10-21  GoldmanSachs   \n",
       "5     2022-10-20  GoldmanSachs   \n",
       "6     2022-10-19  GoldmanSachs   \n",
       "8     2022-10-18  GoldmanSachs   \n",
       "9     2022-10-18  GoldmanSachs   \n",
       "...          ...           ...   \n",
       "12477 2019-09-09          Citi   \n",
       "12484 2019-09-05          Citi   \n",
       "12486 2019-09-05          Citi   \n",
       "12494 2019-09-04          Citi   \n",
       "12495 2019-09-03          Citi   \n",
       "\n",
       "                                           Tweet Content  \n",
       "4      rt @podcast_maze: new episode out now with pet...  \n",
       "5      how are top investors navigating today’s volat...  \n",
       "6      steve and connie ballmer's investment bridges ...  \n",
       "8      rt @squawkcnbc: \"we've got a leading investmen...  \n",
       "9      today we reported our 3q 2022 earnings results...  \n",
       "...                                                  ...  \n",
       "12477  the financial agent mentor-protégé program bui...  \n",
       "12484  \"citi’s $72 million investment in our new stat...  \n",
       "12486  rt @politicopress: can america become a leader...  \n",
       "12494  what are some of the most pressing regulatory ...  \n",
       "12495  in the september issue of @thebanker, #citi co...  \n",
       "\n",
       "[2784 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy to have a back up\n",
    "new_dff = new_df.copy()\n",
    "\n",
    "#Show Dataframe\n",
    "new_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I am adding this next line to provide a solution for the date range differential in the final solution of the correlation between the sentiment and momentum\n",
    "'''\n",
    "\n",
    "# Convert Date to Datetime format.\n",
    "new_dff['Date'] = pd.to_datetime(new_dff['Date'])\n",
    "\n",
    "\n",
    "\n",
    "''' \n",
    "The user name can be switched for the 4 user names ('GoldmanSachs','jpmorgan','BofA_Business','Citi') to filter out different firms to be considered. #greater than the start date and smaller than the end date\n",
    "'''\n",
    "mask = (new_dff['Date'] > '2020-12-31') & (new_dff['Date'] <= '2021-11-30') & (new_dff['User'] == 'jpmorgan')\n",
    "\n",
    "new_dff = new_dff.loc[mask]\n",
    "\n",
    "# Returning the extract to new_df\n",
    "new_df = new_dff.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>agile payments infrastructures are redefining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>the city of lights is exhilarating during #par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>an enchanting city that inspires and connects:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>from machine learning to cybersecurity – techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>from one-on-one mentoring to hands-on experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>where innovation meets insights: j.p. morgan a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>2021-10-15</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>jennifer piepszak believes that taking the lon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      User                                      Tweet Content\n",
       "2793 2021-11-12  jpmorgan  agile payments infrastructures are redefining ...\n",
       "2795 2021-11-12  jpmorgan  the city of lights is exhilarating during #par...\n",
       "2802 2021-11-09  jpmorgan  an enchanting city that inspires and connects:...\n",
       "2806 2021-11-04  jpmorgan  from machine learning to cybersecurity – techn...\n",
       "2808 2021-11-03  jpmorgan  from one-on-one mentoring to hands-on experien...\n",
       "2813 2021-10-25  jpmorgan  where innovation meets insights: j.p. morgan a...\n",
       "2821 2021-10-15  jpmorgan  jennifer piepszak believes that taking the lon..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataframe\n",
    "new_df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_cleaner(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = re.sub(r\"^@\",'@user',text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def emoji_remover(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def text_processing(text):\n",
    "    \"\"\"\n",
    "    - Tokenizes\n",
    "    - Remove stopwords \n",
    "    - Clean text\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    no_punctuation = tweets_cleaner(text)\n",
    "    \n",
    "    tokenized_text = tokenizer.tokenize(no_punctuation)\n",
    "    remove_stopwords = [word for word in tokenized_text if word not in stopwords.words('english')]\n",
    "    combined_text = ' '.join(remove_stopwords)\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "\n",
    "#clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the tweet contents by replacing all unneeded character\n",
    "new_df['Tweet Content'] = new_df['Tweet Content'].apply(lambda x: tweets_cleaner(x))\n",
    "\n",
    "# Removing all emojis\n",
    "new_df['Tweet Content'] = new_df['Tweet Content'].apply(lambda x: emoji_remover(x))\n",
    "\n",
    "# Removing stop words\n",
    "new_df['Tweet Content'] = new_df['Tweet Content'].apply(lambda x: text_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the RoBERTA TimeLMS model importation\n",
    "def import_roberta():\n",
    "    \"\"\"\n",
    "    The function imports all the required model for using the pretrained roberta model\n",
    "    \"\"\"\n",
    "    global tokenizer,roberta,model,labels\n",
    "\n",
    "    # load the roberta model and tokenizer\n",
    "    roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "    # Download the model from the website, USING .from_prtrained loads the model configuration file with the pretrained model weights\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(roberta,from_tf=False)\n",
    "\n",
    "    # Load your tokenizer from the pretrained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(roberta,from_tf=False)\n",
    "\n",
    "    # create labels for your output as stated on the website\n",
    "    labels = ['Negative','Neutral','Positive']\n",
    "\n",
    "\n",
    "import_roberta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sample to test the preprocessing\n",
    "new_df2 = new_df.head(250)\n",
    "\n",
    "# Creating empty lists for functions below \n",
    "result = []\n",
    "opinion_output = []\n",
    "opinion_probability = []\n",
    "\n",
    "# Create a list to house individual  tweet response\n",
    "Negative = []\n",
    "Neutral = []\n",
    "Positive = []\n",
    "\n",
    "# Clear list\n",
    "result.clear()\n",
    "opinion_output.clear()\n",
    "opinion_probability.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentiment classification process\n",
    "\n",
    "def sentiment_model():\n",
    "    \"\"\"\n",
    "    The function processes the sentiment and attaches the result as a new column - Sentiments\n",
    "    \"\"\"\n",
    "    for tweet in new_df2['Tweet Content']:\n",
    "        tweet_processed = tweet\n",
    "        # Encode the processed tweets into a pytorch tensors to be passed into the roberta model \n",
    "        encoded_tweet = tokenizer(tweet_processed,return_tensors= 'pt')\n",
    "        result.append(encoded_tweet)\n",
    "        for i in result:\n",
    "            # Pass the encoded tweet to the model to perform the sentiment analysis on the encode tweets\n",
    "            sentiment_output = model(i['input_ids'],i['attention_mask'])\n",
    "        opinion_output.append(sentiment_output)\n",
    "        #Iterate and extract logit result\n",
    "        for j in opinion_output:\n",
    "            mscores = j[0][0].detach().numpy()\n",
    "            # Convert mscores to probabilities\n",
    "            mscores = softmax(mscores)\n",
    "            # Append the list of sentiments converted as probability into a list\n",
    "            opinion_probability.append(mscores)\n",
    "            # Slice the list to detach various opinion into new columns\n",
    "            for k in opinion_probability:\n",
    "                Neg = k[0]\n",
    "                Neut = k[1]\n",
    "                Pos = k[2]\n",
    "        Negative.append(Neg)\n",
    "        Neutral.append(Neut)\n",
    "        Positive.append(Pos)\n",
    "\n",
    "    #return result,opinion_output,mscores\n",
    "\n",
    "sentiment_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the results into the dataframe \n",
    "new_df2['Negative'] = np.array(Negative)\n",
    "new_df2['Neutral'] = np.array(Neutral)\n",
    "new_df2['Positive'] = np.array(Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Most Likely</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>agile payments infrastructures redefining futu...</td>\n",
       "      <td>0.025943</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.811521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>city lights exhilarating honored partners cons...</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.960864</td>\n",
       "      <td>0.960864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>enchanting city inspires connects art enthusia...</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.247319</td>\n",
       "      <td>0.750760</td>\n",
       "      <td>0.750760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>machine learning cybersecurity technology shap...</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.752064</td>\n",
       "      <td>0.239009</td>\n",
       "      <td>0.752064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>oneonone mentoring handson experience new prog...</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.425706</td>\n",
       "      <td>0.566199</td>\n",
       "      <td>0.566199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>rt cityam exlabour mp chuka umunna hired jpmor...</td>\n",
       "      <td>0.174036</td>\n",
       "      <td>0.800406</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.800406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>three leading executives named diversitywomans...</td>\n",
       "      <td>0.011116</td>\n",
       "      <td>0.797792</td>\n",
       "      <td>0.191092</td>\n",
       "      <td>0.797792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>factors accelerating esg investment flows jp m...</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>0.072876</td>\n",
       "      <td>0.899902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>proud recognized greenwich associates global l...</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.933873</td>\n",
       "      <td>0.933873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>moderna ceo stephane bancel speaks protecting ...</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.732463</td>\n",
       "      <td>0.244573</td>\n",
       "      <td>0.732463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      User                                      Tweet Content  \\\n",
       "2793 2021-11-12  jpmorgan  agile payments infrastructures redefining futu...   \n",
       "2795 2021-11-12  jpmorgan  city lights exhilarating honored partners cons...   \n",
       "2802 2021-11-09  jpmorgan  enchanting city inspires connects art enthusia...   \n",
       "2806 2021-11-04  jpmorgan  machine learning cybersecurity technology shap...   \n",
       "2808 2021-11-03  jpmorgan  oneonone mentoring handson experience new prog...   \n",
       "...         ...       ...                                                ...   \n",
       "3111 2021-02-10  jpmorgan  rt cityam exlabour mp chuka umunna hired jpmor...   \n",
       "3113 2021-02-08  jpmorgan  three leading executives named diversitywomans...   \n",
       "3116 2021-02-03  jpmorgan  factors accelerating esg investment flows jp m...   \n",
       "3121 2021-01-27  jpmorgan  proud recognized greenwich associates global l...   \n",
       "3128 2021-01-13  jpmorgan  moderna ceo stephane bancel speaks protecting ...   \n",
       "\n",
       "      Negative   Neutral  Positive  Most Likely  \n",
       "2793  0.025943  0.811521  0.162536     0.811521  \n",
       "2795  0.001168  0.037968  0.960864     0.960864  \n",
       "2802  0.001921  0.247319  0.750760     0.750760  \n",
       "2806  0.008927  0.752064  0.239009     0.752064  \n",
       "2808  0.008096  0.425706  0.566199     0.566199  \n",
       "...        ...       ...       ...          ...  \n",
       "3111  0.174036  0.800406  0.025559     0.800406  \n",
       "3113  0.011116  0.797792  0.191092     0.797792  \n",
       "3116  0.027222  0.899902  0.072876     0.899902  \n",
       "3121  0.001324  0.064803  0.933873     0.933873  \n",
       "3128  0.022964  0.732463  0.244573     0.732463  \n",
       "\n",
       "[93 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new column houses the maximum most likely sentiment\n",
    "new_df2['Most Likely']= new_df2[[\"Negative\", \"Neutral\",\"Positive\"]].max(axis=1)\n",
    "\n",
    "new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Most Likely</th>\n",
       "      <th>Maximum Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/11/2021</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>agile payments infrastructures redefining futu...</td>\n",
       "      <td>0.025943</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.811521</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/11/2021</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>city lights exhilarating honored partners cons...</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.960864</td>\n",
       "      <td>0.960864</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/11/2021</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>enchanting city inspires connects art enthusia...</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.247319</td>\n",
       "      <td>0.750760</td>\n",
       "      <td>0.750760</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/11/2021</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>machine learning cybersecurity technology shap...</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.752064</td>\n",
       "      <td>0.239009</td>\n",
       "      <td>0.752064</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/11/2021</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>oneonone mentoring handson experience new prog...</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.425706</td>\n",
       "      <td>0.566199</td>\n",
       "      <td>0.566199</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      User                                      Tweet Content  \\\n",
       "0  12/11/2021  jpmorgan  agile payments infrastructures redefining futu...   \n",
       "1  12/11/2021  jpmorgan  city lights exhilarating honored partners cons...   \n",
       "2  09/11/2021  jpmorgan  enchanting city inspires connects art enthusia...   \n",
       "3  04/11/2021  jpmorgan  machine learning cybersecurity technology shap...   \n",
       "4  03/11/2021  jpmorgan  oneonone mentoring handson experience new prog...   \n",
       "\n",
       "   Negative   Neutral  Positive  Most Likely Maximum Sentiment  \n",
       "0  0.025943  0.811521  0.162536     0.811521           Neutral  \n",
       "1  0.001168  0.037968  0.960864     0.960864          Positive  \n",
       "2  0.001921  0.247319  0.750760     0.750760          Positive  \n",
       "3  0.008927  0.752064  0.239009     0.752064           Neutral  \n",
       "4  0.008096  0.425706  0.566199     0.566199          Positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Export the sentiment results to csv file for all users and save for further data manipulation and also to avoid running the model multiple times\n",
    "'''\n",
    "# new_df2.to_csv('BofA_Business.csv', index=False) (change the file name as new models are exported)\n",
    "\n",
    "'''\n",
    "Since I have processed all the above users, I can import the result back without rerunning the model\n",
    "'''\n",
    "# Import results AFTER PERFOMING DATA MANIPULATION IN EXCEL\n",
    "new_df2 = pd.read_csv(r'Jpmorganresult.csv')\n",
    "\n",
    "new_df2.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7020e71a6eb4f20a708e5ba4362220e55a3a390db1a42beccebd061eed296129"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
